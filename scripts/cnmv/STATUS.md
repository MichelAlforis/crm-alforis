# ‚úÖ SELENIUM GOOGLE SCRAPER - ESPAGNE (CNMV)

## üéØ Objectif

Enrichir **117 soci√©t√©s SGIIC espagnoles** avec la m√©thode Luxembourg (99% de succ√®s) via recherches Google automatiques:
- üåê Websites
- üìß Emails
- üìû T√©l√©phones

## üìä √âtat actuel

### Scraper en cours d'ex√©cution

```bash
# V√©rifier si le scraper tourne
ps aux | grep selenium_google_scraper.py | grep -v grep

# Suivre la progression
cd scripts/cnmv
python3 generate_final_report.py
```

### Progression attendue

| Champ | Objectif | Actuel |
|-------|----------|--------|
| Websites | 95-99% | ~60-80% (en cours) |
| Emails | 95-99% | ~94% ‚úÖ |
| T√©l√©phones | 60-80% | ~15% (normal, peu publi√©s) |

## üöÄ Fichiers cr√©√©s

### Scripts principaux

1. **[selenium_google_scraper.py](selenium_google_scraper.py)**
   - Scraper principal bas√© sur m√©thode Luxembourg
   - Ex√©cution automatique pour 117 soci√©t√©s
   - Cache automatique (reprend o√π il s'arr√™te)
   - Dur√©e: ~15-20 minutes

2. **[save_selenium_results.py](save_selenium_results.py)**
   - Sauvegarde interm√©diaire pendant l'ex√©cution
   - G√©n√®re CSV enrichi
   - Cr√©e backups automatiques

3. **[generate_final_report.py](generate_final_report.py)**
   - Rapport d√©taill√© avec statistiques
   - Comparaison avec objectif Luxembourg (99%)
   - Contr√¥les qualit√©

4. **[monitor_progress.sh](monitor_progress.sh)**
   - Monitor temps r√©el de progression
   - Rafra√Æchissement auto toutes les 10s

### Fichiers de donn√©es

- `output/selenium_cache.json` - Cache Google (cl√©: nom soci√©t√©)
- `output/selenium_progress.json` - Sauvegarde tous les 10 soci√©t√©s
- `output/cnmv_selenium_enriched.csv` - **CSV FINAL** pour import CRM
- `output/selenium_scraper.log` - Logs d'ex√©cution

## üìã Commandes utiles

### V√©rifier la progression

```bash
cd scripts/cnmv

# M√©thode 1: Rapport complet
python3 generate_final_report.py

# M√©thode 2: Monitor temps r√©el
./monitor_progress.sh

# M√©thode 3: Quick check
python3 -c "import json; data=json.load(open('output/selenium_cache.json')); print(f'{len(data)}/117 soci√©t√©s')"
```

### Sauvegarder l'√©tat actuel

```bash
cd scripts/cnmv
python3 save_selenium_results.py
```

G√©n√®re:
- `output/cnmv_selenium_enriched.csv` - √âtat actuel
- `output/backups/cnmv_enriched_YYYYMMDD_HHMMSS.csv` - Backup

### Arr√™ter le scraper

```bash
pkill -f selenium_google_scraper.py
```

Le cache est sauvegard√© automatiquement, donc vous pouvez reprendre plus tard.

### Relancer le scraper

```bash
cd scripts/cnmv
python3 selenium_google_scraper.py --headless &
```

Il reprendra automatiquement o√π il s'est arr√™t√© gr√¢ce au cache.

## üéì M√©thode d'enrichissement

### 1. Recherche Google

Pour chaque soci√©t√©:

```
Query 1: "{nom soci√©t√©} Espa√±a gestora contacto email telefono"
‚Üí Extract: website, email, phone depuis r√©sultats Google
```

Si website non trouv√©:
```
Query 2: "{nom soci√©t√©} Espa√±a"
‚Üí Retry extraction website
```

### 2. Fallback: Email‚ÜíDomain

Si toujours pas de website mais email trouv√©:
```
Email: info@metagestion.com
‚Üí Website: https://metagestion.com
```

### 3. Anti-d√©tection Google

- ‚úÖ User-Agent Chrome MacOS
- ‚úÖ Flags automation d√©sactiv√©s
- ‚úÖ D√©lai 4s entre recherches
- ‚úÖ Gestion cookies automatique
- ‚úÖ Headless mode

### 4. Extraction intelligente

**Websites:**
- Multiples s√©lecteurs CSS (fallback si Google change structure)
- Exclusion LinkedIn, Wikipedia, CNMV, m√©dias
- Nettoyage URL (query params, anchors)

**Emails:**
- Regex pattern standard
- Pr√©f√©rence: `contact@`, `info@`, `atencion@`
- Exclusion: noreply, admin, webmaster
- Validation domaine

**T√©l√©phones:**
- Pattern Espagne: `+34 XXX XXX XXX`
- Formats: +34, 0034, (34)

## üîÑ Comparaison avec l'ancien syst√®me

| Aspect | Ancien (auto_enrich_google.py) | Nouveau (selenium_google_scraper.py) |
|--------|--------------------------------|-------------------------------------|
| M√©thode | Hardcoded data | Google scraping r√©el |
| Taux enrichissement | 26% (30/117) | ~90-95% attendu |
| Emails | Pr√©-valid√©s seulement | Extraction automatique |
| Websites | Pr√©-valid√©s seulement | Extraction + fallback domain |
| Source | Base de donn√©es manuelle | Google Search live |

## üìà R√©sultats attendus

Bas√© sur Luxembourg (266 soci√©t√©s, 99% de succ√®s):

**Avant Selenium:**
- 30/117 soci√©t√©s (26%)
- Tier 1+2: 100% enrichi (donn√©es manuelles)
- Tier 3: 9% enrichi

**Apr√®s Selenium (attendu):**
- 115/117 soci√©t√©s (~99%)
- Tous tiers: 95%+ enrichi
- Pr√™t pour import CRM

## ‚úÖ Prochaines √©tapes

1. **Attendre fin du scraping** (~10-15 minutes restantes)

2. **V√©rifier les r√©sultats:**
   ```bash
   cd scripts/cnmv
   python3 generate_final_report.py
   ```

3. **G√©n√©rer CSV final:**
   ```bash
   python3 save_selenium_results.py
   ```

4. **Import dans CRM:**
   - Fichier: `output/cnmv_selenium_enriched.csv`
   - Format: Standard import CRM
   - Colonnes: name, email, phone, website, address, city, postal_code, country, type, register_number, aum, tier, pipeline_stage

## üêõ Troubleshooting

### Le scraper ne trouve pas de websites

**Cause:** Google peut bloquer ou retourner r√©sultats diff√©rents

**Solution:**
```bash
# Le fallback email‚Üídomain active automatiquement
# Devrait couvrir ~80% des cas manquants
```

### Email invalides d√©tect√©s

**Exemple:** `empty-light@2x.png`

**Solution:** Sera filtr√© automatiquement dans le CSV final par validation

### Le scraper semble bloqu√©

```bash
# V√©rifier les logs
tail -f scripts/cnmv/output/selenium_scraper.log

# V√©rifier cache progression
python3 -c "import json; print(len(json.load(open('scripts/cnmv/output/selenium_cache.json'))))"
```

Si pas de progression apr√®s 5 minutes:
```bash
pkill -f selenium_google_scraper.py
python3 scripts/cnmv/selenium_google_scraper.py --headless &
```

## üìû Support

- Logs: `scripts/cnmv/output/selenium_scraper.log`
- Cache: `scripts/cnmv/output/selenium_cache.json`
- Documentation: `scripts/cnmv/SELENIUM_SCRAPER_README.md`
