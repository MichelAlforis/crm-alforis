#!/usr/bin/env python3
"""
GÃ©nÃ¨re un rapport final de l'enrichissement Selenium
Compare avec les objectifs Luxembourg (99%)
"""

import json
import csv
from pathlib import Path
from datetime import datetime

BASE_DIR = Path(__file__).parent
CACHE_FILE = BASE_DIR / "output/selenium_cache.json"
OUTPUT_CSV = BASE_DIR / "output/cnmv_selenium_enriched.csv"

def generate_report():
    print("=" * 80)
    print("  RAPPORT FINAL - ENRICHISSEMENT SELENIUM ESPAÃ‘A (CNMV)")
    print("=" * 80)
    print()

    # Load cache
    if not CACHE_FILE.exists():
        print("âŒ Cache file not found")
        return

    with open(CACHE_FILE, 'r', encoding='utf-8') as f:
        cache = json.load(f)

    total = len(cache)
    target = 117

    # Calculate stats
    with_website = sum(1 for v in cache.values() if v.get('website'))
    with_email = sum(1 for v in cache.values() if v.get('email'))
    with_phone = sum(1 for v in cache.values() if v.get('phone'))

    complete_all = sum(1 for v in cache.values() if v.get('website') and v.get('email') and v.get('phone'))
    complete_web_email = sum(1 for v in cache.values() if v.get('website') and v.get('email'))

    # Progress
    print(f"ğŸ“Š PROGRESSION GLOBALE")
    print(f"   SociÃ©tÃ©s scrapÃ©es: {total}/{target} ({total/target*100:.1f}%)")
    print()

    # Enrichment rates
    print(f"ğŸ“ˆ TAUX D'ENRICHISSEMENT")
    print(f"   ğŸŒ Websites:      {with_website:>3}/{total:>3}  ({with_website/total*100:.1f}%)")
    print(f"   ğŸ“§ Emails:        {with_email:>3}/{total:>3}  ({with_email/total*100:.1f}%)")
    print(f"   ğŸ“ TÃ©lÃ©phones:    {with_phone:>3}/{total:>3}  ({with_phone/total*100:.1f}%)")
    print()
    print(f"   âœ… Complet (W+E+P): {complete_all:>3}/{total:>3}  ({complete_all/total*100:.1f}%)")
    print(f"   âœ… Complet (W+E):   {complete_web_email:>3}/{total:>3}  ({complete_web_email/total*100:.1f}%)")
    print()

    # Compare with Luxembourg target (99%)
    luxembourg_target = 99.0
    print(f"ğŸ¯ COMPARAISON AVEC LUXEMBOURG (objectif: {luxembourg_target}%)")

    web_diff = with_website/total*100 - luxembourg_target
    email_diff = with_email/total*100 - luxembourg_target

    web_status = "âœ…" if web_diff >= -5 else "âš ï¸" if web_diff >= -15 else "âŒ"
    email_status = "âœ…" if email_diff >= -5 else "âš ï¸" if email_diff >= -15 else "âŒ"

    print(f"   {web_status} Websites:  {with_website/total*100:.1f}% (Ã©cart: {web_diff:+.1f}%)")
    print(f"   {email_status} Emails:    {with_email/total*100:.1f}% (Ã©cart: {email_diff:+.1f}%)")
    print()

    # Quality checks
    print(f"ğŸ” CONTRÃ”LE QUALITÃ‰")

    # Check for invalid emails
    invalid_emails = []
    for name, data in cache.items():
        email = data.get('email', '')
        if email and ('.png' in email or len(email) < 5 or '@' not in email):
            invalid_emails.append((name, email))

    if invalid_emails:
        print(f"   âš ï¸  {len(invalid_emails)} email(s) invalide(s) dÃ©tectÃ©(s)")
        for name, email in invalid_emails[:3]:
            print(f"      - {name[:50]}: {email}")
    else:
        print(f"   âœ… Tous les emails valides")

    # Check for invalid websites
    invalid_websites = []
    for name, data in cache.items():
        website = data.get('website', '')
        if website and not website.startswith('http'):
            invalid_websites.append((name, website))

    if invalid_websites:
        print(f"   âš ï¸  {len(invalid_websites)} website(s) invalide(s)")
        for name, website in invalid_websites[:3]:
            print(f"      - {name[:50]}: {website}")
    else:
        print(f"   âœ… Tous les websites valides")
    print()

    # Top companies by tier (if available)
    print(f"ğŸ† TOP SOCIÃ‰TÃ‰S ENRICHIES")

    # Load original data with tiers
    input_json = BASE_DIR / "output/cnmv_all_sgiic_raw.json"
    if input_json.exists():
        with open(input_json, 'r', encoding='utf-8') as f:
            original_data = {c['name']: c for c in json.load(f)}

        # Merge with cache
        tier1_complete = []
        for name, data in cache.items():
            if data.get('website') and data.get('email'):
                orig = original_data.get(name, {})
                tier = orig.get('tier', 'Unknown')
                aum = orig.get('aum', 0)
                if tier == 'Tier 1' or aum > 1_000_000_000:
                    tier1_complete.append((name, data, aum))

        tier1_complete.sort(key=lambda x: x[2], reverse=True)

        if tier1_complete:
            print(f"   Tier 1 enrichies (AUM â‰¥ 1Bnâ‚¬): {len(tier1_complete)}")
            for name, data, aum in tier1_complete[:5]:
                aum_bn = aum / 1_000_000_000 if aum else 0
                print(f"      â€¢ {name[:45]} ({aum_bn:.1f}Bnâ‚¬)")
                print(f"        ğŸŒ {data['website']}")

    print()

    # Recommendations
    print(f"ğŸ’¡ RECOMMANDATIONS")

    if total < target:
        remaining = target - total
        print(f"   â³ Attendre la fin du scraping ({remaining} sociÃ©tÃ©s restantes)")

    if with_website/total*100 < 90:
        print(f"   ğŸ”§ AmÃ©liorer l'extraction des websites (actuellement {with_website/total*100:.0f}%)")
        print(f"      â†’ VÃ©rifier les sÃ©lecteurs CSS")
        print(f"      â†’ Augmenter le fallback emailâ†’domain")

    if with_phone/total*100 < 50:
        print(f"   ğŸ“ TÃ©lÃ©phones: taux faible normal (standards souvent non publiÃ©s)")

    if invalid_emails:
        print(f"   ğŸ§¹ Nettoyer les {len(invalid_emails)} emails invalides")

    print()
    print("=" * 80)

    # Save timestamp
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"\nğŸ“… Rapport gÃ©nÃ©rÃ© le: {timestamp}")
    print(f"ğŸ’¾ Cache: {CACHE_FILE}")
    print(f"ğŸ’¾ CSV final: {OUTPUT_CSV}")
    print()

if __name__ == '__main__':
    generate_report()
