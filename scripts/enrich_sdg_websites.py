#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enrichissement des sites web manquants pour les SDG fran√ßaises via recherche Google
"""

import pandas as pd
import time
import json
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

BASE_DIR = Path(__file__).parent.parent

def setup_driver():
    """Configure le driver Selenium"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--lang=fr-FR')
    chrome_options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')

    driver = webdriver.Chrome(options=chrome_options)
    return driver

def search_website_google(driver, company_name):
    """Recherche le site web d'une entreprise via Google"""
    try:
        query = f"{company_name} soci√©t√© de gestion site officiel"
        url = f"https://www.google.com/search?q={query.replace(' ', '+')}"

        driver.get(url)
        time.sleep(2)

        # Chercher le premier r√©sultat organique
        results = driver.find_elements(By.CSS_SELECTOR, 'div.g a')

        for result in results[:3]:  # Top 3 r√©sultats
            href = result.get_attribute('href')
            if href and href.startswith('http'):
                # Exclure les sites non pertinents
                excluded = ['linkedin.com', 'wikipedia.org', 'societe.com', 'pappers.fr',
                           'infogreffe.fr', 'verif.com', 'manageo.fr', 'google.com']

                if not any(exc in href for exc in excluded):
                    return href

        return None

    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return None

def main():
    print("üîç Enrichissement des sites web manquants\n")

    # Charger le CSV
    csv_file = BASE_DIR / 'SDG_FRANCE_677_CONSOLIDATED_FOR_CRM.csv'
    df = pd.read_csv(csv_file)

    print(f"üìä {len(df)} organisations charg√©es")

    # Corriger le champ country ‚Üí FR
    print("\nüîß Correction du champ 'country' ‚Üí FR")
    df['country'] = 'FR'

    # Identifier les sites manquants
    missing_websites = df[(df['website'].isna()) | (df['website'] == '')]
    print(f"\nüåê {len(missing_websites)} sites web manquants")

    if len(missing_websites) == 0:
        print("‚úÖ Tous les sites web sont pr√©sents !")
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        return

    # Charger le cache s'il existe
    cache_file = BASE_DIR / 'data' / 'sdg_france_website_cache.json'
    cache_file.parent.mkdir(exist_ok=True)

    if cache_file.exists():
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache = json.load(f)
        print(f"üì¶ Cache charg√©: {len(cache)} entr√©es")
    else:
        cache = {}

    # Lancer Selenium
    print("\nüöÄ D√©marrage de la recherche Google...\n")
    driver = setup_driver()

    enriched = 0
    errors = 0

    try:
        for idx, row in missing_websites.iterrows():
            company_name = row['name']

            # V√©rifier le cache
            if company_name in cache:
                website = cache[company_name]
                if website:
                    df.at[idx, 'website'] = website
                    enriched += 1
                    print(f"‚úì [{enriched}/{len(missing_websites)}] {company_name[:50]:<50} ‚Üí {website} (cache)")
                continue

            print(f"üîç [{enriched+1}/{len(missing_websites)}] {company_name[:50]:<50}", end=' ‚Üí ')

            website = search_website_google(driver, company_name)

            if website:
                df.at[idx, 'website'] = website
                cache[company_name] = website
                enriched += 1
                print(f"‚úÖ {website}")
            else:
                cache[company_name] = None
                errors += 1
                print("‚ùå Non trouv√©")

            # Sauvegarder le cache tous les 10
            if (enriched + errors) % 10 == 0:
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(cache, f, indent=2, ensure_ascii=False)

            time.sleep(3)  # Pause entre les requ√™tes

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interruption par l'utilisateur")
    finally:
        driver.quit()

        # Sauvegarder le cache final
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ Cache sauvegard√©: {cache_file}")

    # Sauvegarder le CSV mis √† jour
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')

    print(f"\nüìä R√âSULTATS:")
    print(f"  ‚úÖ {enriched} sites trouv√©s")
    print(f"  ‚ùå {errors} non trouv√©s")
    print(f"  üìà Taux de compl√©tion: {(len(df) - (df['website'].isna() | (df['website'] == '')).sum()) / len(df) * 100:.1f}%")
    print(f"\n‚úÖ Fichier mis √† jour: {csv_file.name}")

if __name__ == '__main__':
    main()
