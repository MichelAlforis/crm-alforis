# ğŸ§ª Tests CRM Backend

Guide complet pour les tests automatisÃ©s du backend.

---

## ğŸ“¦ Installation

```bash
cd crm-backend

# Installer les dÃ©pendances de test
pip install -r requirements-test.txt
```

---

## ğŸš€ Lancer les Tests

### Tous les tests

```bash
# Lancer tous les tests
pytest

# Avec coverage
pytest --cov=. --cov-report=html

# En parallÃ¨le (plus rapide)
pytest -n auto
```

### Tests spÃ©cifiques

```bash
# Un fichier
pytest tests/test_organisations.py

# Une fonction
pytest tests/test_organisations.py::test_create_organisation

# Une classe
pytest tests/test_organisations.py::TestOrganisationAPI

# Par marker
pytest -m unit  # Seulement les tests unitaires
pytest -m "not slow"  # Tous sauf les lents
```

### VerbositÃ©

```bash
# Plus de dÃ©tails
pytest -v

# Encore plus de dÃ©tails
pytest -vv

# Afficher les prints
pytest -s
```

---

## ğŸ“Š Coverage

### GÃ©nÃ©rer le rapport

```bash
# Terminal
pytest --cov=. --cov-report=term-missing

# HTML (ouvrir htmlcov/index.html)
pytest --cov=. --cov-report=html

# XML (pour CI/CD)
pytest --cov=. --cov-report=xml
```

### Objectif Coverage

- **Backend:** 70%+
- **ModÃ¨les:** 90%+
- **API Routes:** 80%+
- **Services:** 70%+

---

## ğŸ—ï¸ Structure des Tests

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py              # Fixtures communes
â”œâ”€â”€ test_auth.py             # Tests authentification
â”œâ”€â”€ test_organisations.py    # Tests organisations âœ…
â”œâ”€â”€ test_people.py           # Tests personnes âœ…
â”œâ”€â”€ test_mandats.py          # Tests mandats/produits
â”œâ”€â”€ test_imports.py          # Tests imports CSV/Excel
â””â”€â”€ test_api_integration.py  # Tests end-to-end
```

---

## ğŸ› ï¸ Fixtures Disponibles

### Database

```python
def test_something(test_db):
    # test_db = session SQLite en mÃ©moire
    org = Organisation(name="Test")
    test_db.add(org)
    test_db.commit()
```

### Client HTTP

```python
def test_api(client, auth_headers):
    # client = TestClient FastAPI
    # auth_headers = {"Authorization": "Bearer ..."}
    response = client.get("/api/v1/organisations", headers=auth_headers)
    assert response.status_code == 200
```

### Utilisateurs

```python
def test_with_user(test_user):
    # test_user = User de test
    assert test_user.email == "test@example.com"

def test_with_admin(admin_user):
    # admin_user = Admin de test
    assert admin_user.role == UserRole.ADMIN
```

### Organisations

```python
def test_with_org(sample_organisation):
    # Une organisation de test
    assert sample_organisation.name == "Test Company"

def test_with_orgs(sample_organisations):
    # 5 organisations de test
    assert len(sample_organisations) == 5
```

### Personnes

```python
def test_with_person(sample_person):
    # Une personne de test
    assert sample_person.first_name == "John"

def test_with_linked_person(sample_person_with_org):
    # Personne liÃ©e Ã  une organisation
    assert len(sample_person_with_org.organizations) >= 1
```

### Factories

```python
def test_with_factory(test_db, create_organisation):
    # Factory pour crÃ©er des organisations custom
    org = create_organisation(
        test_db,
        name="Custom Org",
        category=OrganisationCategory.CGPI
    )
    assert org.name == "Custom Org"
```

---

## âœ… Ã‰crire un Nouveau Test

### Test Unitaire (ModÃ¨le)

```python
# tests/test_organisations.py

def test_create_organisation(test_db):
    """Test crÃ©ation d'une organisation"""
    org = Organisation(
        name="New Company",
        category=OrganisationCategory.INSTITUTION,
        email="contact@newcompany.com",
    )

    test_db.add(org)
    test_db.commit()
    test_db.refresh(org)

    assert org.id is not None
    assert org.name == "New Company"
```

### Test API (Integration)

```python
# tests/test_organisations.py

def test_list_organisations_api(client, auth_headers, sample_organisations):
    """Test liste des organisations via API"""
    response = client.get(
        "/api/v1/organisations",
        headers=auth_headers
    )

    assert response.status_code == 200
    data = response.json()
    assert len(data) == 5
```

### Test avec Mock

```python
import pytest
from unittest.mock import patch

def test_external_api_call(client, auth_headers):
    """Test avec mock d'une API externe"""
    with patch('services.external_api.fetch_data') as mock_fetch:
        mock_fetch.return_value = {"data": "mocked"}

        response = client.get("/api/v1/external", headers=auth_headers)

        assert response.status_code == 200
        assert response.json() == {"data": "mocked"}
        mock_fetch.assert_called_once()
```

---

## ğŸ·ï¸ Markers

### Utiliser les markers

```python
import pytest

@pytest.mark.slow
def test_slow_operation():
    # Test qui prend du temps
    pass

@pytest.mark.integration
def test_full_workflow():
    # Test end-to-end
    pass

@pytest.mark.unit
def test_pure_function():
    # Test unitaire
    pass
```

### Lancer par marker

```bash
# Seulement les tests unitaires
pytest -m unit

# Tous sauf les lents
pytest -m "not slow"

# Tests API seulement
pytest -m api
```

---

## ğŸ› Debugging

### Afficher les prints

```bash
pytest -s
```

### ArrÃªter au premier Ã©chec

```bash
pytest -x
```

### Afficher les traceback complets

```bash
pytest --tb=long
```

### Mode debug interactif

```bash
# Ajouter dans le test
import pdb; pdb.set_trace()

# Ou utiliser pytest
pytest --pdb  # S'arrÃªte au premier Ã©chec
```

### Logs dÃ©taillÃ©s

```bash
pytest --log-cli-level=DEBUG
```

---

## ğŸ“ˆ CI/CD

### GitHub Actions

```yaml
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Run tests
        run: |
          pytest --cov=. --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
```

---

## ğŸ¯ Best Practices

### 1. Nommage

```python
# âœ… Bon
def test_create_organisation_with_valid_data():
    pass

# âŒ Mauvais
def test1():
    pass
```

### 2. One Assertion Per Test (idÃ©alement)

```python
# âœ… Bon
def test_organisation_has_name():
    org = Organisation(name="Test")
    assert org.name == "Test"

def test_organisation_has_email():
    org = Organisation(email="test@example.com")
    assert org.email == "test@example.com"

# âŒ Mauvais
def test_organisation():
    org = Organisation(name="Test", email="test@example.com")
    assert org.name == "Test"
    assert org.email == "test@example.com"
    assert org.is_active is True
    # Trop d'assertions diffÃ©rentes
```

### 3. Arrange-Act-Assert

```python
def test_update_organisation():
    # Arrange (PrÃ©parer)
    org = Organisation(name="Old Name")
    db.add(org)
    db.commit()

    # Act (Agir)
    org.name = "New Name"
    db.commit()

    # Assert (VÃ©rifier)
    assert org.name == "New Name"
```

### 4. Utiliser des Fixtures

```python
# âœ… Bon
def test_list_organisations(client, auth_headers, sample_organisations):
    response = client.get("/api/v1/organisations", headers=auth_headers)
    assert len(response.json()) == len(sample_organisations)

# âŒ Mauvais
def test_list_organisations(client):
    # CrÃ©er les donnÃ©es de test ici
    # CrÃ©er l'auth ici
    # Puis tester
    pass
```

### 5. Nettoyer aprÃ¨s le Test

```python
# âœ… La fixture test_db nettoie automatiquement

# âŒ Si vous gÃ©rez manuellement
def test_something():
    try:
        # Test
        pass
    finally:
        # Nettoyer
        pass
```

---

## ğŸ“š Exemples Complets

### Test CRUD Complet

```python
def test_organisation_crud(client, auth_headers):
    """Test CRUD complet d'une organisation"""

    # Create
    create_response = client.post(
        "/api/v1/organisations",
        json={"name": "CRUD Test", "category": "Institution"},
        headers=auth_headers
    )
    assert create_response.status_code == 201
    org_id = create_response.json()["id"]

    # Read
    read_response = client.get(
        f"/api/v1/organisations/{org_id}",
        headers=auth_headers
    )
    assert read_response.status_code == 200
    assert read_response.json()["name"] == "CRUD Test"

    # Update
    update_response = client.put(
        f"/api/v1/organisations/{org_id}",
        json={"name": "CRUD Updated"},
        headers=auth_headers
    )
    assert update_response.status_code == 200
    assert update_response.json()["name"] == "CRUD Updated"

    # Delete
    delete_response = client.delete(
        f"/api/v1/organisations/{org_id}",
        headers=auth_headers
    )
    assert delete_response.status_code == 204

    # Verify deleted
    verify_response = client.get(
        f"/api/v1/organisations/{org_id}",
        headers=auth_headers
    )
    assert verify_response.status_code == 404
```

---

## ğŸ†˜ Troubleshooting

### ProblÃ¨me: "No module named 'X'"

```bash
# VÃ©rifier l'installation
pip list | grep X

# RÃ©installer
pip install -r requirements-test.txt
```

### ProblÃ¨me: "Database is locked"

```python
# Utiliser la fixture test_db qui gÃ¨re SQLite en mÃ©moire
def test_something(test_db):
    # Pas de problÃ¨me de lock
    pass
```

### ProblÃ¨me: Tests lents

```bash
# Lancer en parallÃ¨le
pytest -n auto

# Profiler
pytest --durations=10  # Affiche les 10 tests les plus lents
```

### ProblÃ¨me: Fixtures not found

```python
# VÃ©rifier que conftest.py est bien dans tests/
tests/
â”œâ”€â”€ conftest.py  â† Doit Ãªtre ici
â””â”€â”€ test_*.py
```

---

## ğŸ“Š Commandes Utiles

```bash
# Lancer tous les tests avec coverage
pytest --cov=. --cov-report=html

# Tests spÃ©cifiques
pytest tests/test_organisations.py -v

# Voir les tests disponibles
pytest --collect-only

# Lancer les tests marquÃ©s
pytest -m unit

# Lancer en parallÃ¨le
pytest -n 4  # 4 workers

# Mode watch (relancer auto Ã  chaque changement)
pip install pytest-watch
ptw
```

---

## ğŸ‰ Conclusion

Vous avez maintenant:
- âœ… Structure de tests complÃ¨te
- âœ… Fixtures rÃ©utilisables
- âœ… Tests organisations et personnes
- âœ… Configuration pytest et coverage
- âœ… Guide complet d'utilisation

**Prochaine Ã©tape:** Ã‰crire les tests manquants (auth, mandats, imports)

**Objectif:** Coverage > 70%

---

**Happy Testing! ğŸ§ª**
