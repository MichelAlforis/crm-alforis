# ===========================================
# DOCKER COMPOSE - PRODUCTION
# ===========================================
# Configuration optimisée pour la production
# - Chargement automatique de .env (natif Docker Compose)
# - Build optimisé avec multi-stage
# - Healthchecks robustes
# - Logs limités avec rotation
# - Variables d'environnement sécurisées

# IMPORTANT: Créer un fichier .env à la racine avec:
# - POSTGRES_PASSWORD
# - SECRET_KEY
# - ALLOWED_ORIGINS
# - NEXT_PUBLIC_API_URL

# --- Réseau ---
networks:
  crm-network:
    driver: bridge

# --- Volumes ---
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  api-uploads:
    driver: local
  api-backups:
    driver: local
  caddy-data:
    driver: local
  caddy-config:
    driver: local
  caddy-logs:
    driver: local
  ollama-models:
    driver: local

# --- Services ---
services:

  # ========================================
  # CADDY (Reverse Proxy + SSL/TLS Auto)
  # ========================================
  caddy:
    image: caddy:2.7-alpine
    restart: always
    ports:
      - "80:80"      # HTTP (redirect to HTTPS)
      - "443:443"    # HTTPS
      - "443:443/udp"  # HTTP/3 (QUIC)
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
      - caddy-logs:/var/log/caddy
    networks:
      - crm-network
    depends_on:
      - api
      - frontend
    environment:
      - DOMAIN=${DOMAIN:-crm.alforis.fr}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:2019/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # REDIS (Cache & Event Bus)
  # ========================================
  redis:
    image: redis:7-alpine
    restart: always
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru --appendonly yes
    ports:
      - "127.0.0.1:${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    networks:
      - crm-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # POSTGRES
  # ========================================
  postgres:
    image: postgres:16-alpine
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-crm_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD doit être défini dans .env}
      POSTGRES_DB: ${POSTGRES_DB:-crm_db}
      PGDATA: /var/lib/postgresql/data/pgdata
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=128MB"
      - "-c"
      - "work_mem=4MB"
      - "-c"
      - "maintenance_work_mem=64MB"
      - "-c"
      - "effective_cache_size=512MB"
      - "-c"
      - "max_connections=50"
    ports:
      # Utiliser un port différent pour éviter les conflits avec PostgreSQL local
      - "127.0.0.1:${POSTGRES_EXTERNAL_PORT:-5433}:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - crm-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h 127.0.0.1 -p 5432 -U ${POSTGRES_USER:-crm_user} -d postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # API (FastAPI)
  # ========================================
  api:
    build:
      context: ./crm-backend
      dockerfile: Dockerfile
      target: production
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    # Docker Compose charge automatiquement .env à la racine
    environment:
      # URL de connexion PostgreSQL (utilise le nom du service 'postgres')
      DATABASE_URL: postgresql://${POSTGRES_USER:-crm_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-crm_db}
      # Redis Cache & Event Bus
      REDIS_ENABLED: "True"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      # Ollama (AI Local LLM)
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.1:latest}
      # Sécurité
      DEBUG: "False"
      SECRET_KEY: ${SECRET_KEY:?SECRET_KEY doit être défini dans .env}
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS:-["https://crm.alforis.fr"]}
      # JWT
      JWT_ALGORITHM: ${JWT_ALGORITHM:-HS256}
      JWT_EXPIRATION_HOURS: ${JWT_EXPIRATION_HOURS:-24}
      # AI Agent - Encryption
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:?ENCRYPTION_KEY doit être défini dans .env}
      # Environnement
      ENVIRONMENT: production
      MAX_UPLOAD_SIZE_MB: ${MAX_UPLOAD_SIZE_MB:-10}
      API_PORT: 8000
    working_dir: /app
    # Production: 4 workers, pas de logs d'accès pour les perfs
    command: uvicorn main:app --host 0.0.0.0 --port ${API_PORT:-8000} --proxy-headers
    ports:
      - "127.0.0.1:${API_PORT:-8000}:8000"
    volumes:
      - api-uploads:/app/uploads
      - api-backups:/app/backups
    networks:
      - crm-network
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request;urllib.request.urlopen(\"http://localhost:8000/api/v1/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # ========================================
  # FRONTEND (Next.js)
  # ========================================
  frontend:
    build:
      context: ./crm-frontend
      dockerfile: Dockerfile
      target: production
      args:
        # Passer l'URL de l'API au build - Lit depuis .env racine
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-/api/v1}
    restart: always
    depends_on:
      api:
        condition: service_healthy
    # Docker Compose charge automatiquement .env à la racine
    environment:
      # URL de l'API accessible depuis le navigateur
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-/api/v1}
      NODE_ENV: production
      PORT: ${FRONTEND_PORT:-3010}
    working_dir: /app
    command: npm start
    ports:
      - "127.0.0.1:${FRONTEND_PORT:-3010}:${FRONTEND_PORT:-3010}"
    networks:
      - crm-network
    healthcheck:
      # Healthcheck plus robuste qui vérifie vraiment la disponibilité
      test: ["CMD-SHELL", "node -e 'require(\"http\").get(\"http://localhost:${FRONTEND_PORT:-3010}\",r=>process.exit(r.statusCode>=200&&r.statusCode<500?0:1)).on(\"error\",()=>process.exit(1))'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # ========================================
  # OLLAMA (Local LLM for AI features)
  # ========================================
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "127.0.0.1:11434:11434"
    networks:
      - crm-network
    volumes:
      - ollama-models:/root/.ollama
    environment:
      # Config optimisée pour production
      OLLAMA_MAX_LOADED_MODELS: 1           # 1 modèle en mémoire
      OLLAMA_NUM_PARALLEL: 2                # 2 requêtes parallèles
      OLLAMA_MAX_QUEUE: 5                   # Queue jusqu'à 5 requêtes
      OLLAMA_KEEP_ALIVE: 5m                 # Garde modèle 5min en RAM
    deploy:
      resources:
        limits:
          cpus: '2.0'      # 2 CPU sur 4 (50%)
          memory: 5G       # 5GB max
        reservations:
          cpus: '1.0'      # Démarre avec 1 CPU
          memory: 2G       # 2GB minimum
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
